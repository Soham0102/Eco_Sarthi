# import google.generativeai as genai
# import json
# import re
# from dotenv import load_dotenv
# import os

# load_dotenv()
# API_KEY = os.getenv("AIzaSyDUClq0SgIcsHqjtQzpHpr7FcPkyVQMWOM")
# genai.configure(api_key=API_KEY)
# model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")

# PROMPT_TEMPLATE = """
# ‡§§‡•Å‡§Æ ‡§è‡§ï ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§π‡•ã...  # shortened for brevity
# Conversation:
# {conversation_log}
# """


# def ask_gemini_followup_or_result(conversation_log):
#     prompt = PROMPT_TEMPLATE.format(conversation_log=conversation_log)
#     response = model.generate_content(prompt)
#     text = response.text.strip()
#     print("üîÅ Gemini Response:", text)
#     return text


# def is_structured_json(text):
#     try:
#         match = re.search(r"\{[\s\S]*\}", text)
#         if match:
#             parsed = json.loads(match.group())
#             if "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§" in parsed:
#                 return parsed
#     except json.JSONDecodeError:
#         return None
#     return None

# import google.generativeai as genai
# import json
# import re

# # ‚úÖ Use your API key directly
# #AIzaSyDQ8agyfEwaijZ0VpByd1I71cnzIuKuXvc
# #AIzaSyDUClq0SgIcsHqjtQzpHpr7FcPkyVQMWOM
# API_KEY = "AIzaSyDQ8agyfEwaijZ0VpByd1I71cnzIuKuXvc"
# genai.configure(api_key=API_KEY)

# # Gemini model
# model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")

# # ‚úÖ Only ONE correct version of this function
# def ask_gemini_followup_or_result(conversation_log):
#     prompt = f"""
#     ‡§§‡•Å‡§Æ ‡§è‡§ï ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§¨‡•ã‡§ü ‡§π‡•ã ‡§ú‡•ã ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§∏‡•á ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§è‡§ï-‡§è‡§ï ‡§ï‡§∞ ‡§ï‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§≤‡•á‡§§‡•Ä ‡§π‡•ã‡•§

#     ‡§Ö‡§≠‡•Ä ‡§§‡§ï ‡§ï‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§:
#     {conversation_log}

#     ‡§Ö‡§¨ ‡§ú‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§≤‡•Ä ‡§ó‡§à ‡§π‡•à, ‡§ï‡•á‡§µ‡§≤ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§ó‡§≤‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•ã‡•§
#     ‡§Ø‡§¶‡§ø ‡§∏‡§≠‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§ø‡§≤ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï JSON ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ã ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§´‡§º‡•Ä‡§≤‡•ç‡§° ‡§π‡•ã‡§Ç:
#     {{
#       "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§": "...",
#       "‡§∏‡•ç‡§•‡§æ‡§®": "...",
#       "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ": "...",
#       "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞": "...",
#       "‡§¨‡•ã‡§≤‡§®‡•á_‡§≤‡§æ‡§Ø‡§ï_‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂": "...",
#       "‡§Ö‡§Ç‡§§‡§ø‡§Æ_‡§ò‡•ã‡§∑‡§£‡§æ": "...",
#       "‡§µ‡§ø‡§≠‡§æ‡§ó": "..."
#     }}
#     """
#     response = model.generate_content(prompt)
#     text = response.text.strip()
#     print("ü§ñ Gemini Response:", text)  # Optional for debugging
#     return text

# # ‚úÖ JSON detection logic
# def is_structured_json(text):
#     try:
#         match = re.search(r"\{[\s\S]*\}", text)
#         if match:
#             parsed = json.loads(match.group())
#             if "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§" in parsed:
#                 return parsed
#     except json.JSONDecodeError:
#         return None
#     return None



import google.generativeai as genai
import json
import re
import time
from datetime import datetime

# ‚úÖ Use your API key directly
API_KEY = "AIzaSyDQ8agyfEwaijZ0VpByd1I71cnzIuKuXvc"
genai.configure(api_key=API_KEY)

# Gemini model
model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")

# Cache for reducing API calls
response_cache = {}


def generate_complaint_id():
    """Generate unique complaint ID"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    return f"CMP-{timestamp}"


def get_department_from_complaint(complaint_text):
    """Simple rule-based department detection to save API calls"""
    complaint_lower = complaint_text.lower()
    
    # Road related
    if any(word in complaint_lower for word in ["‡§∏‡§°‡§º‡§ï", "‡§ó‡§°‡•ç‡§¢‡§æ", "road", "street", "pothole"]):
        return "‡§∏‡§°‡§º‡§ï ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Water related
    elif any(word in complaint_lower for word in ["‡§™‡§æ‡§®‡•Ä", "‡§®‡§≤", "water", "tap", "pipe"]):
        return "‡§ú‡§≤ ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Electricity related
    elif any(word in complaint_lower for word in ["‡§¨‡§ø‡§ú‡§≤‡•Ä", "light", "electricity", "power"]):
        return "‡§µ‡§ø‡§¶‡•ç‡§Ø‡•Å‡§§ ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Sanitation related
    elif any(word in complaint_lower for word in ["‡§ï‡•Ç‡§°‡§º‡§æ", "‡§ó‡§Ç‡§¶‡§ó‡•Ä", "garbage", "waste", "cleaning"]):
        return "‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ‡§§‡§æ ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Health related
    elif any(word in complaint_lower for word in ["‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤", "doctor", "health", "medical"]):
        return "‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Education related
    elif any(word in complaint_lower for word in ["‡§∏‡•ç‡§ï‡•Ç‡§≤", "school", "education", "teacher"]):
        return "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§µ‡§ø‡§≠‡§æ‡§ó"
    
    # Default
    else:
        return "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§™‡•ç‡§∞‡§∂‡§æ‡§∏‡§®"


def ask_gemini_followup_or_result(conversation_log):
    """
    Simplified version - only use AI for complex cases
    This saves API quota for your free account
    """
    
    # Check cache first
    cache_key = hash(conversation_log)
    if cache_key in response_cache:
        return response_cache[cache_key]
    
    # Simple prompt to save tokens
    prompt = f"""
    ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§: {conversation_log}
    
    ‡§Ö‡§ó‡§≤‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•ã ‡§Ø‡§æ JSON ‡§¨‡§®‡§æ‡§ì:
    {{
      "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§": "...",
      "‡§∏‡•ç‡§•‡§æ‡§®": "...",
      "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ": "...",
      "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞": "...",
      "‡§µ‡§ø‡§≠‡§æ‡§ó": "..."
    }}
    """
    
    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        # Cache the response
        response_cache[cache_key] = text
        
        print("ü§ñ Gemini Response:", text[:100] + "..." if len(text) > 100 else text)
        return text
        
    except Exception as e:
        print(f"‚ùå Gemini API Error: {e}")
        # Fallback response
        return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"


def ask_smart_followup(current_data, missing_fields):
    """
    Smart followup questions without using API
    This saves your quota significantly
    """
    
    if "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§" in missing_fields:
        return "‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? ‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
    
    elif "‡§∏‡•ç‡§•‡§æ‡§®" in missing_fields:
        return "‡§Ø‡§π ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§π‡§æ‡§Å ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à? ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§™‡§§‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
    
    elif "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ" in missing_fields:
        return "‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?"
    
    elif "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞" in missing_fields:
        return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§π‡§Æ ‡§Ü‡§™‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞ ‡§∏‡§ï‡•á‡§Ç‡•§"
    
    else:
        # All info collected, create final JSON
        department = get_department_from_complaint(current_data.get("‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§", ""))
        
        final_data = {
            "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§": current_data.get("‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§", ""),
            "‡§∏‡•ç‡§•‡§æ‡§®": current_data.get("‡§∏‡•ç‡§•‡§æ‡§®", ""),
            "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ": current_data.get("‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ", ""),
            "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞": current_data.get("‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞", ""),
            "‡§µ‡§ø‡§≠‡§æ‡§ó": department,
            "complaint_id": generate_complaint_id(),
            "‡§¨‡•ã‡§≤‡§®‡•á_‡§≤‡§æ‡§Ø‡§ï_‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂": f"‡§Ü‡§™‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ {department} ‡§ï‡•ã ‡§≠‡•á‡§ú‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§",
            "‡§Ö‡§Ç‡§§‡§ø‡§Æ_‡§ò‡•ã‡§∑‡§£‡§æ": "‡§Ü‡§™‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§¶‡§∞‡•ç‡§ú ‡§π‡•ã ‡§ó‡§à ‡§π‡•à‡•§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!"
        }
        
        return json.dumps(final_data, ensure_ascii=False)


def is_structured_json(text):
    """Enhanced JSON detection logic"""
    try:
        # Look for JSON pattern
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            json_str = match.group()
            parsed = json.loads(json_str)
            
            # Check if it's a complaint JSON
            if "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§" in parsed or "complaint" in str(parsed).lower():
                return parsed
                
        # Try to parse the entire text as JSON
        parsed = json.loads(text)
        if isinstance(parsed, dict) and "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§" in parsed:
            return parsed
            
    except (json.JSONDecodeError, AttributeError):
        pass
    
    return None


def validate_phone_number(phone):
    """Simple phone number validation"""
    import re
    # Remove spaces and common characters
    phone = re.sub(r'[^\d]', '', phone)
    
    # Check if it's a valid Indian mobile number
    if len(phone) == 10 and phone.startswith(('6', '7', '8', '9')):
        return True
    elif len(phone) == 13 and phone.startswith('91'):
        return True
    
    return False


def create_final_complaint(complaint_data):
    """Create final complaint JSON with all validations"""
    
    # Validate required fields
    required_fields = ["‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§", "‡§∏‡•ç‡§•‡§æ‡§®", "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ", "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞"]
    
    for field in required_fields:
        if not complaint_data.get(field, "").strip():
            return None
    
    # Validate phone number
    if not validate_phone_number(complaint_data["‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞"]):
        return None
    
    # Get department
    department = get_department_from_complaint(complaint_data["‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§"])
    
    # Create final structure
    final_complaint = {
        "complaint_id": generate_complaint_id(),
        "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§": complaint_data["‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§"].strip(),
        "‡§∏‡•ç‡§•‡§æ‡§®": complaint_data["‡§∏‡•ç‡§•‡§æ‡§®"].strip(),
        "‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ": complaint_data["‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ"].strip(),
        "‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞": complaint_data["‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§®‡§Ç‡§¨‡§∞"].strip(),
        "‡§µ‡§ø‡§≠‡§æ‡§ó": department,
        "timestamp": datetime.now().isoformat(),
        "status": "‡§¶‡§∞‡•ç‡§ú",
        "priority": "medium",
        "‡§¨‡•ã‡§≤‡§®‡•á_‡§≤‡§æ‡§Ø‡§ï_‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂": f"‡§Ü‡§™‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ {generate_complaint_id()[:8]} ‡§¶‡§∞‡•ç‡§ú ‡§π‡•ã ‡§ó‡§à ‡§π‡•à‡•§ ‡§Ø‡§π {department} ‡§ï‡•ã ‡§≠‡•á‡§ú‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§",
        "‡§Ö‡§Ç‡§§‡§ø‡§Æ_‡§ò‡•ã‡§∑‡§£‡§æ": "‡§Ü‡§™‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§¶‡§∞‡•ç‡§ú ‡§π‡•ã ‡§ó‡§à ‡§π‡•à‡•§ ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§∞‡§µ‡§æ‡§à ‡§ï‡•Ä ‡§ú‡§æ‡§è‡§ó‡•Ä‡•§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!"
    }
    
    return final_complaint